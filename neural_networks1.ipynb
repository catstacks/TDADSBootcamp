{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight init\n",
    "\n",
    "# Assume these two network layers\n",
    "input_layer = 50   #number of neurons\n",
    "hidden_layer = 25  #number of neurons\n",
    "\n",
    "# Random weights with values between 0 and 1\n",
    "W1 = np.random.randn(hidden_layer, input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# He init\n",
    "\n",
    "# Assume these two network layers\n",
    "input_layer = 50   #number of neurons\n",
    "hidden_layer = 25  #number of neurons\n",
    "\n",
    "# Random weights drom Gaussian distribution (mean = 0, variance = 1)\n",
    "W1 = np.random.randn(hidden_layer, input_layer)\n",
    "\n",
    "# Weights normalisation: He\n",
    "W1 = W1 * np.sqrt(2 / hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xavier init\n",
    "\n",
    "# Assume these two network layers\n",
    "input_layer = 50   #number of neurons\n",
    "hidden_layer = 25  #number of neurons\n",
    "\n",
    "# Random weights drom Gaussian distribution (mean = 0, variance = 1)\n",
    "W1 = np.random.randn(hidden_layer, input_layer)\n",
    "\n",
    "# Weights normalisation: He\n",
    "W1 = W1 * np.sqrt(1 / hidden_layer)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
